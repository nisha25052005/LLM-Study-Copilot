# ðŸ“š LLM Study Copilot (RAG-Based AI Study Assistant)

The **LLM Study Copilot** is a Retrieval-Augmented Generation (**RAG**)â€“powered study tool that turns uploaded PDF notes into interactive learning material.
It can **answer questions**, **summarize notes**, **generate MCQs**, and **create flashcards** using a **local LLM (Qwen2.5-0.5B-Instruct)** â€” no API keys or paid services needed.

Built with **Python, Streamlit, FAISS, Sentence Transformers**, and **HuggingFace Transformers**.

---

#  Features

###  1. Ask Questions From Your PDF Notes (RAG)

* Upload multiple PDFs
* Extracts + chunks text
* Creates embeddings using Sentence Transformers
* Uses FAISS for semantic search
* Retrieves relevant chunks and answers using your notes only
* Page numbers included

###  2. LLM-Powered Answers (Local Offline Qwen Model)

* Runs **Qwen2.5-0.5B-Instruct** locally
* Provides contextual, grounded answers
* No API keys â†’ No cost â†’ Full privacy

###  3. Automatic Summaries

* 10â€“15 bullet-point summaries
* Key definitions, formulas, concepts

###  4. MCQ Generator

* Generates exam-style MCQs
* Options Aâ€“D
* Correct answer shown

###  5. Flashcard Creator

* Produces concise Qâ€“A flashcards
* Perfect for quick revision

###  6. Streamlit UI

Simple interface with:

* PDF Upload
* Knowledge Base Builder
* Ask Questions
* Generate Summary / MCQs / Flashcards

---

#  Project Architecture

PDF â†’ Extract Text â†’ Chunk â†’ Embed â†’ Store in FAISS
Query â†’ Embed â†’ Retrieve Relevant Chunks â†’ Build Prompt â†’ Qwen Answer

This ensures **low hallucination**, **fast retrieval**, and **accurate context-based answers**.

---

#  Tech Stack

**Frontend:** Streamlit
**Backend:** Python
**Embeddings:** Sentence Transformers (MiniLM-L6-v2)
**Vector Store:** FAISS
**LLM:** Qwen2.5-0.5B-Instruct (HuggingFace)
**PDF Processing:** PyPDF2
**Frameworks:** Transformers, Accelerate

---

#  Folder Structure

study-copilot/
â”‚â”€â”€ app.py
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ pdf_utils.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â””â”€â”€ llm.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚â”€â”€ venv/ (ignored)

---

#  How to Replicate This Project (Step-by-Step)

Anyone can run this project locally by following the instructions below.

---

##  **1. Clone the Repository**

```
git clone https://github.com/YOUR_USERNAME/study-copilot.git
cd study-copilot
```

Replace `YOUR_USERNAME` with your GitHub username.

---

##  **2. Create a Virtual Environment**

```
python -m venv venv
```

Activate it:

Windows:

```
venv\Scripts\activate
```

Mac/Linux:

```
source venv/bin/activate
```

---

##  **3. Install All Dependencies**

If you have `requirements.txt`:

```
pip install -r requirements.txt
```

If not, install manually:

```
pip install streamlit PyPDF2 sentence-transformers faiss-cpu transformers accelerate torch sentencepiece safetensors numpy python-dotenv
```

---

##  **4. Download the LLM Automatically**

The first time you run the project, Hugging Face will automatically download:

```
Qwen/Qwen2.5-0.5B-Instruct
```

No API key needed.

---

##  **5. Run the Application**

```
streamlit run app.py
```

You should see:

```
Local URL: http://localhost:8501
```

Open it in your browser.

---

##  **6. Use the App**

1. Upload one or more PDFs
2. Click **Build Knowledge Base**
3. Ask any question
4. Or generate:

   * Summary
   * MCQs
   * Flashcards

Enjoy! 
Everything runs **fully offline**.

---

# requirements.txt (For Replication)

Include this in your repo:

```
streamlit
PyPDF2
sentence-transformers
faiss-cpu
transformers
accelerate
torch
sentencepiece
safetensors
numpy
python-dotenv
```

---

# Future Enhancements

* Support DOCX / PPT / Image OCR
* Multiple model selector (Qwen, TinyLlama, Mistral, Phi)
* Export MCQs/Flashcards to PDF
* User authentication + cloud storage
* UI improvements

---

#  Credits

* Hugging Face (Transformers + Qwen model)
* FAISS
* Streamlit
* Sentence Transformers


